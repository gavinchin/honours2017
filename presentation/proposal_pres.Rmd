---
title: "Modelling the City of Melbourne Pedestrian Data"
subtitle: "Thesis Proposal"
author: "Gavin Chin, supervised by Di Cook"
date: "8 May 2017"
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE, echo = FALSE, warning=FALSE, message=FALSE}
options(htmltools.dir.version = FALSE, scipen = 100)
library(readr)
library(dplyr)
library(ggplot2)
library(ggmap)
library(knitr)
library(lubridate)
  ped_df <- read_csv("../data/Pedestrian_volume__updated_monthly_.csv")
      
  ped_loc <- read_csv("../data/Pedestrian_sensor_locations.csv")
  
  melb <- get_map(location=c(mean(range(ped_loc$Longitude)),
                               mean(range(ped_loc$Latitude))),
                                zoom=14)
  melbbw <- get_map(location=c(mean(range(ped_loc$Longitude)),
                               mean(range(ped_loc$Latitude))),
                                zoom=14,
                    color = "bw")
```

class: center

# Introduction

The City of Melbourne has an Open Data Platform which makes council data available to the public  

This project will focus on the pedestrian sensor data

```{r, echo = FALSE, fig.height=5, fig.retina = 3}
ggmap(melb) + geom_point(aes(x = Longitude, y = Latitude), data = ped_loc, colour = "red", alpha = 0.7) +
              labs(title = "Melbourne Pedestrian Sensor Locations") +
              xlab(NULL) + ylab(NULL) +
              theme(plot.title = element_text(hjust = 0.5), plot.caption = element_text(hjust = 0.5),
                    axis.text.x = element_blank(), axis.text.y = element_blank(),
                    axis.ticks = element_blank())
```


---
class: center

## How is the data collected?

The City of Melbourne has `r nrow(ped_loc)` sensors installed around Melbourne's CBD  
- These sensors are positioned under an awning or street pole, and count the number of people passing each hour
- The data is available as a `.csv` at https://data.melbourne.vic.gov.au/, and is updated monthly

![figure of pedestrian sensors](../img/ped_sensors.png)

_source: http://www.pedestrian.melbourne.vic.gov.au/ _

---


# Why do we want to model pedestrian traffic?

### Being able to predict how many people pass through a certain location can be used by the government sector as well as the private sector  

#### Different ways it can be used: 

  Government example uses:  
    - Infrastructure planning
    - Security planning
  Private example uses:
    - Marketing campaign planning
    - Resource management
    - Investment planning
  
  and many other various ways..
---

class: center, middle

## Time series at each sensor location


```{r, echo = FALSE, message=FALSE, warning=FALSE}
      ped_df$Year <- as.factor(ped_df$Year)
      ped_df$Month <- as.factor(ped_df$Month)
      ped_df$Month <- factor(ped_df$Month, levels(ped_df$Month)[c(5,4,8,1,9,7,6,2,12,11,10,3)])
      ped_df$Time <- as.factor(ped_df$Time)
      ped_df$Timeplot <- as.integer(ped_df$Time)
      ped_df$MTime <- as.integer(ped_df$Time) + ((as.integer(ped_df$Mdate)-1) * 24)
      ped_df$Day <- as.factor(ped_df$Day)
      ped_df$Day <- factor(ped_df$Day, levels(ped_df$Day)[c(2,6,7,5,1,3,4)])
      
      ped_df$Lat <- 0
      ped_df$Lon <- 0
      
      for (i in 1:dim(ped_loc)[1])
      {
      ped_df$Lat[ped_df$Sensor_ID == ped_loc$`Sensor ID`[i]] <- ped_loc$Latitude[i]
      ped_df$Lon[ped_df$Sensor_ID == ped_loc$`Sensor ID`[i]] <- ped_loc$Longitude[i]
      }

```

```{r, message= FALSE, warning= FALSE, fig.height = 5, fig.width = 12, echo = FALSE, fig.retina = 2, fig.align= "center"}
bsplot <- ped_df %>% filter(Year == "2016", Month == "June", Mdate < 25, Sensor_ID == "40")
ggplot(bsplot) + geom_line(aes(x = MTime, y = Hourly_Counts), colour = "black") + ggtitle(paste("Hourly Pedestrian Count at", unique(bsplot$Sensor_Name), sep = " "), subtitle = "during June 2016") +
      xlab("Hour of the Month") + ylab("Hourly Counts") + theme_light()
```

#### Basic variables available are: time and date, sensor ID and hourly counts

```{r, echo = FALSE}
head(ped_df[, -c(11,12)], 1)
```


---

## Multiple seasonal patterns

#### For example, at Flagstaff Station, we notice a couple of key patterns:
- Weekly cycle
```{r, message= FALSE, warning= FALSE, fig.height = 3, fig.width = 12, echo = FALSE, fig.retina = 2, fig.align= "center"}
bsplot <- ped_df %>% filter(Year == "2016", Month == "June", Mdate < 25, Sensor_ID == "13")
ggplot(bsplot) + geom_line(aes(x = MTime, y = Hourly_Counts)) + ggtitle("Hourly Pedestrian Count at Flagstaff Station", subtitle = "during June 2016") +
      xlab("Hour of the Month") + ylab("Hourly Counts") + theme_light()
```
- Daily sub-cycle
```{r, message= FALSE, warning= FALSE, fig.height=3, echo = FALSE, fig.align= "center", fig.retina = 2}
ggplot(filter(ped_df, Sensor_ID == "13")) + geom_path(aes(x = as.integer(Time), y = Hourly_Counts, colour = Day), alpha = 0.2) +
      xlab("Hour of the Day") + ylab("Hourly Counts") + theme_light() +
      guides(colour = guide_legend(override.aes = list(alpha = 1)))
```

---
class: inverse, middle, center

# Methodology

### The project has been split into multiple steps:  
#### Data Cleaning
#### Modelling
#### Visualisation
#### Shiny app development
  
---

# Data Cleaning: Problems in the data

### While the data variables themselves are relatively tidy, there is a large number of observations we need to impute:


```{r, echo = FALSE, fig.align = "center", fig.height=6, fig.width=12, fig.retina = 2}
ped_plot <- aggregate(x = ped_df$Hourly_Counts,
                      by = list("Sensor_ID" = ped_df$Sensor_ID, "Year" = ped_df$Year, "Month" = ped_df$Month),
                      FUN = sum)

ped_plot$counts <- ped_plot$x


ped_plot$Time <- parse_date(paste(ped_plot$MDate, ped_plot$Month, ped_plot$Year,
                                  sep = "-"), format = "%D-%B-%Y")

ped_plot$ID <- as.integer(ped_plot$Sensor_ID)

ped_plot$Sensor_ID <- as.factor(ped_plot$Sensor_ID)

ggplot(filter(ped_plot)) + geom_line(aes(x = Time, y = counts, colour = Sensor_ID)) + theme_light() +
  theme(legend.position = "none") + labs(x = "Year", y = "Pedestrian Counts") + ggtitle("Monthly Total Counts by Sensor")

```

---

# Data Cleaning: Imputing the missings

#### A simple way to impute these missings is estimating a Poisson regression using GLM in R:

```{r, eval = FALSE}
missing_glm <- glm(Hourly_Counts ~ Year * HDay * Time + Month,
                   data = ped_df, family = "poisson")
```

This can be expressed as:

$$\text{HourlyCounts} \sim\text{Year}\times\text{HDay}\times\text{Time}+\text{Month}$$
$$\Rightarrow\qquad \log{\lambda_{i}}  =\beta_{0}+\beta_{1}\text{Year}\times\text{HDay}\times\text{Time}+\beta_{2}\text{Month}$$
$$\text{HourlyCounts}_{i}  =\text{Poisson}\left(\lambda_{i}\right)$$

--

- This model specification implies an interaction effect between the year, time of the day, and day of the week (or if the day is a public holiday)
  + Month of the year is modelled as an additive effect 

- The model needs to be estimated for each location, due to the different characteristics between locations

---

# Modelling

- Main purpose of the model is to forecast pedestrian counts
- Data used for estimatation (training dataset) will be the period between 2014-2016
  + The data before 2014 is not stable, and also lacks data from newly installed sensors
- Data used to evaluate the forecasting performance will be the 2017 data available

- Due to the multiple seasonal patterns in the time series, typical models like AR, ARMA and ARIMA do not work very well
  + Modelling using other sources of data is being explored, in particular weather data
  + Alternative models, such as a Multiple Seasonal (MS) process available through the `forecast` R package, should also be investigated
  + Machine learning techniques, such as clustering and other non-parametric estimation methods, will also be considered

---
class: middle, center

## Modelling: evaluating model performance
The criteria we will use to evaluate the model's forecasting performance is the root mean square forecast error:
$$ \text{RMSFE} = \sqrt{\frac{\sum_{t=T+1}^{T+k}(\hat{y_t} - y_t)^2}{k}}$$
where the model is estimated with $T$ observations, and we have $k$ points to forecast (so we need to have $T+k$ observations available)
- evaluating performance of the model on its forecasting accuracy is important, as it will reveal overfitting of data

---

class: center, middle

## Visualisation: Currently available
#### Official City of Melbourne data visualisation

```{r, echo = FALSE, out.height= "400px", out.width = "540px"}
include_graphics("../img/ped_vis_melb.PNG")
```

---
class: center, middle

## Visualisation

With this project, we want to improve the way we visualise Melbourne's pedestrian activity
```{r, echo = FALSE, fig.retina = 3, out.height="500px", fig.align = 'center'}
ggmap(melbbw) + geom_point(aes(x = Lon, y = Lat, size = Hourly_Counts), colour = "red", alpha = 0.03, data = filter(ped_df, Year == "2016", Month == "January", Time == "9")) + scale_size_area(max_size = 10) + scale_color_distiller(palette = "PuOr") + guides(colour = guide_legend(override.aes = list(alpha = 1))) + theme_light() + labs(x = NULL, y = NULL)
```

---
class: center

## Visualisation: different methods

```{r, echo = FALSE, message=FALSE, out.height="480px", fig.retina=2, fig.width = 12}
  ggplot(ped_df[ped_df$Sensor_ID == "3", ]) + 
    geom_smooth(aes(x = Timeplot, y = Hourly_Counts, colour = Month), se = F) + 
    xlab("Time of the Day") + ylab("Pedestrian Count") + 
    ggtitle(paste("Monthly Average Hourly Counts at", ped_loc$`Sensor Description`[ped_loc$`Sensor ID` == "3"], "by Day")) +
    facet_wrap(~ Day, nrow = 2) + theme(plot.title = element_text(hjust = 0.5), legend.position = "bottom") +
    scale_x_continuous(limits = c(0,24))
```

---

class: center

## Visualisation: different methods

```{r, echo = FALSE, message=FALSE, out.height="480px", fig.retina=2, fig.width = 12}
  ggplot(ped_df[ped_df$Sensor_ID == "3", ]) + 
    geom_density(aes(x = Hourly_Counts, colour = Day), adjust = 2, alpha = 0.2) + 
    xlab("Pedestrian Counts") + ylab("Density") + 
    ggtitle(paste("Kernel Density Estimates of Hourly Counts at", ped_loc$`Sensor Description`[ped_loc$`Sensor ID` == "3"], "by Day")) +
    theme(plot.title = element_text(hjust = 0.5), legend.position = "bottom")
```

---
class: middle

## Visualisation: importance of design

As we can see, there are many different ways to present the same data  

When designing visualisations for pedestrian data, we need to take into consideration:
- Preattentive processing
- Change blindness

Need to communicate the intended message to the person viewing the plots

---
class: center

## Interactive Visualisation: Shiny apps

The package `shiny` allows us to build web apps using R's capabilities in the background  

We can add interactive inputs to visualisations

#### An example of what we can make:


---

class: inverse, middle

# Research Plan

### The plan to approach this research project is as follows:

1. Imputation that incorporates time and space
2. Creating a predictive model for each sensor
3. Investigation of visual methods for space-time counts
4. Development of a Shiny app: interface design, computation and data backend
5. Generation of a dynamic spatial model (if time permits)

---

class: inverse, middle, center

# Questions or comments?

---

# Acknowledgements

##### Thanks to Di Cook and Earo Wang for helping me thus far in the project!

This presentation was written in R Markdown using the template `xaringan`.
Other packages used for this presentation are: `readr, dplyr, ggplot2, ggmap, knitr, lubridate`


