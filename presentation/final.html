<!DOCTYPE html>
<html>
  <head>
    <title>Modelling the City of Melbourne Pedestrian Data</title>
    <meta charset="utf-8">
    <meta name="author" content="Gavin Chin, supervised by Di Cook" />
    <link href="libs/remark-css/example.css" rel="stylesheet" />
    <link rel="stylesheet" href="myremark.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Modelling the City of Melbourne Pedestrian Data
## Thesis Presentation
### Gavin Chin, supervised by Di Cook
### 2 October 2017

---




class: center

# Introduction

The City of Melbourne has an Open Data Platform which makes council data available to the public  

This project will focus on the pedestrian sensor data

&lt;img src="final_files/figure-html/unnamed-chunk-1-1.png" width="504" /&gt;


---
class: middle

## How is the data collected?

The City of Melbourne has 43 sensors installed around Melbourne's CBD  
- These sensors are positioned under an awning or street pole, and count the number of people passing each hour

&lt;img src="../img/ped_sensors.png" width="852px" height="369px" style="display: block; margin: auto;" /&gt;

_source: http://www.pedestrian.melbourne.vic.gov.au/_

---
class: middle
## Accessing the data

- The data is available as a `.csv` at https://data.melbourne.vic.gov.au/, and is updated monthly
- Alternatively, the data is also available as daily data from http://www.pedestrian.melbourne.vic.gov.au/
  * The `rwalkr` R package by Earo Wang provides an API to access the data from both sources easily in R in a tidy format
- Both sources of data provide the same counts data, but have different forms

We use the daily data sourced from `pedestrian.melbourne.vic.gov.au` rather than the data available at the Open Data Platform as missing values are explicit
- accessible using `rwalkr::walk_melb()`

---

# Format of the data
#### Variables available:
- Time and date, sensor ID/location and hourly pedestrian count (volume)


```
## # A tibble: 1,409,712 x 5
##                  Sensor  Date_Time       Date  Time Count
##                   &lt;chr&gt;     &lt;date&gt;     &lt;date&gt; &lt;int&gt; &lt;int&gt;
## 1         State Library 2014-01-01 2014-01-01     0  1709
## 2 Collins Place (South) 2014-01-01 2014-01-01     0   893
## 3 Collins Place (North) 2014-01-01 2014-01-01     0   404
## 4     Flagstaff Station 2014-01-01 2014-01-01     0   462
## # ... with 1.41e+06 more rows
```


&lt;img src="final_files/figure-html/unnamed-chunk-5-1.png" width="720" /&gt;

---
class: center
# The Problem: Prediction of pedestrian traffic
&lt;img src="final_files/figure-html/unnamed-chunk-6-1.png" width="720" /&gt;


- Different locations have different counts and patterns
- We want to predict using 2014-2016 data to train our model

---
## Why do we want to model pedestrian traffic?

### Being able to predict how many people pass through a certain location can be used by the government sector as well as the private sector  

#### Examples ways it can be used: 

- Government example uses:  
  * Infrastructure planning
  * Security planning
- Private example uses:
  * Marketing campaign planning
  * Resource management
  * Investment planning
---
class: middle, center
# Missing Data
&lt;img src="final_files/figure-html/unnamed-chunk-7-1.png" width="864" /&gt;

- Some small and large periods of missing data
- We need to impute these values before building a predictive model
---

## Imputation of missing values

- A simple approach of using a single model specification at all locations did not work well
  * Some sensors had large proportions of missing data, particularly pre-2015
- Need to use different model for sensors with large proportion of missing values and those with a small proportion of missing values



&lt;img src="final_files/figure-html/unnamed-chunk-8-1.png" width="504" style="display: block; margin: auto;" /&gt;

---
class: middle
# Imputation Algorithm

#### Needed to develop an algorithm to:

- **Step 1:** Find which sensors have a "large" proportion of missing values  
- **Step 2:** At each sensor location, run appropriate GLM model with quasipoisson error distribution for imputation  
  * if "small", use GLM with `Hourly_Counts` as response variable and time and date based variables as predictors
  * if "large", use GLM with `Hourly_Counts` as response variable and neighbouring sensor counts as predictors
- **Step 3:** Replace missing values with imputed values  

---
## Step 1: Calculating proportion of missing values
- Need to first fix potential false zero-count values
  * Some observations of `Count = 0` may actually be missing values
  * Include a check for long periods with zero count, and replace with `NA` if too long
- Classify sensors as "small" or "large" proportion of missing values with a threshold proportion
  * We used 10% as the threshold proportion

&lt;img src="final_files/figure-html/unnamed-chunk-9-1.png" width="504" style="display: block; margin: auto;" /&gt;


---
class: middle, center
## Step 1: Classification of sensors by "small" and "large" proportion of  missing values

&lt;img src="final_files/figure-html/unnamed-chunk-10-1.png" width="792" style="display: block; margin: auto;" /&gt;

---

## Step 2a: Fit models at sensors with "small" proportion of missing values

At each sensor location with small proportion of missing values, we estimate a generalised linear model with:
`$$\mu_{\text{Sensor}, \text{Month}, \text{DayType}, \text{Time}} \sim \text{Month} + \text{Time}\times \text{DayType}$$`
and a quaispoisson error distribution.
- Quasipoisson regression allows for `\(Var[\text{HourlyCount}] = \theta \mu\)` (ie. overdispersion)
- These models only use time and date based variables to predict pedestrian counts
  * `DayType` is a factor level/categorical variable based on the day of the week and public holidays
  * `Time` is treated as a factor level, as it has a non-linear relationship with counts

---

## Step 2b: Replacing missing values with imputed values

- Need to fill the missing data at the sensors with small proportions of missing values first
  * The imputation models at sensors with large proportions of missing values are based on neighbouring sensors
  * Requires complete data at neighbours to work properly

&lt;img src="final_files/figure-html/unnamed-chunk-11-1.png" width="720" /&gt;


---
class: middle
## Step 2c: Find neighbours for sensors with "large" proportion of missing values

&lt;img src="final_files/figure-html/unnamed-chunk-12-1.png" width="504" style="display: block; margin: auto;" /&gt;
- Need to use data from neighbouring sensors
- Neighbour defined as geographical neighbours for simplicity
  * Find two closest sensors by great-circle (haversine) distance

---
class: center, middle
## _Step 2c: Fit find neighbours sensors with "large" proportion of missing values_




&lt;img src="final_files/figure-html/unnamed-chunk-14-1.png" width="720" /&gt;

- Need to standardise counts at neighbours to match patterns

---
class: middle
## _Step 2c: Fit models using neighbours_
At each sensor location with "large" proportion of missing values, we estimate a generalised linear model with:  

`$$\mu_{\text{Time}, \text{HourlyCounts}_{\text{neighbours}}^{SC}} \sim \text{Time} \times \text{HourlyCounts}_{\text{neighbour 1}}^{SC} + \text{Time} \times \text{HourlyCounts}_{\text{neighbour 2}}^{SC}$$`

and a quaispoisson error distribution.  

- use interaction with `Time`, the hour of the day, and the scaled counts at neighbours
  * Again, `Time` is treated as a factor variable
  * Counts scaled by standardising each sensor to `\(\mu = 0\)` and `\(\sigma^2 = 1\)`

---
## Step 3: Replacing missing values with imputed values

Using the models estimated, we can impute the missing values
- For sensors with large proportion of missing values, we needed to have complete data at the neighbours
  * Can't use neighbours with large proportion of missing values
  * Use imputed data from sensors with small proportion of missing values

&lt;img src="final_files/figure-html/unnamed-chunk-15-1.png" width="720" /&gt;

---
class: middle
# Implementation of the imputation algorithm

- general code which will run the algorithm
- inputs required: 
  * data in wide format
  * threshold value for missing values proportion (_default:_ `threshold = 0.1`)
  * max length of repeated values (_default:_ `maxlength = 17`)
- use R and RStudio with packages:
  * `dplyr`, `lubridate` and `tidyr` for data manipulation
  * `foreach` and `doSNOW` for parallel computing
  * `rwalkr` for accessing latest data
---
## Imputation Model Evaluation
### In-sample Fit

&lt;img src="final_files/figure-html/unnamed-chunk-16-1.png" width="648" /&gt;


```r
MARE_glm_tr &lt;- numeric()
for (i in unique(ped_data$Sensor)){
  MARE_glm_tr[i] &lt;- mean(abs(fitted_data[[i]] - unlist(dfa[, i])), na.rm = T) / mean(unlist(dfa[, i]), na.rm = T)
}
```

---
class: center, middle
## Imputation Model Evaluation
### Out-of-sample cross validation


&lt;img src="final_files/figure-html/unnamed-chunk-19-1.png" width="252" /&gt;

&lt;img src="final_files/figure-html/unnamed-chunk-20-1.png" width="720" /&gt;

---

# Predictive model using imputed data
- can perform analysis at all locations now with complete data
&lt;img src="final_files/figure-html/unnamed-chunk-21-1.png" width="720" /&gt;
- can treat each specific hour of the week as a time series
  * find covariates outside the counts data to help predict counts
  * eg. weather data, public events

### Objective: On the fly predictions of pedestrian traffic
- requires efficient data storage

---
# Future steps for final paper
- develop Shiny app wih RStudio to provide on the fly predictions
- explore predictors outide of counts data
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {window.dispatchEvent(new Event('resize'));});
(function() {var d = document, s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler"); if (!r) return; s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }"; d.head.appendChild(s);})();</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
  }
});
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
